{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmqRKKEBES+ERHBHbrJgHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivoSorhie/Sephora-Reviews-Sentiment-Analysis/blob/main/Sephora__Product_Risk_Mitigation_via_NLP_Sentiment_Analysis_notebook_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Project Setup & Data Loading**\n",
        "***\n",
        "* **Import Libraries:** We will import all packages upfront, including `pandas`, `seaborn`, `nltk`, and `transformers`.\n",
        "* **Load Data:** We will upload the `sephora_sample_data.csv` (which i have already cleaned from a prior dataset) file to our Colab environment and load it into a pandas DataFrame named `df_sample`, which will be our primary dataset for the entire project."
      ],
      "metadata": {
        "id": "do6yLT-19kDR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maM5q4_O9hHY"
      },
      "outputs": [],
      "source": [
        "# Install required libraries silently\n",
        "!pip install -q transformers datasets squarify\n",
        "\n",
        "# --- 1.1: Import All Necessary Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import squarify\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from google.colab import files\n",
        "\n",
        "# Download NLTK data required for text cleaning\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set a default style and size for all our plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "print(\"All libraries installed and imported successfully!\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 1.2: Upload and Load the Dataset ---\n",
        "print(\"Please upload your 'sephora_sample_data.csv' file.\")\n",
        "\n",
        "# Prompt for file upload\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded file and load it\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "try:\n",
        "    df_sample = pd.read_csv(io.StringIO(uploaded[file_name].decode('utf-8')))\n",
        "    print(f\"\\nFile '{file_name}' uploaded and loaded successfully!\")\n",
        "    print(f\"DataFrame 'df_sample' created with {df_sample.shape[0]} rows and {df_sample.shape[1]} columns.\")\n",
        "\n",
        "    # Display the first few rows and info to confirm it's correct\n",
        "    print(\"\\n--- DataFrame Info ---\")\n",
        "    df_sample.info()\n",
        "    print(\"\\n--- DataFrame Head ---\")\n",
        "    display(df_sample.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Data Cleaning and EDA**"
      ],
      "metadata": {
        "id": "O2lyPZ6OAcJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Raw Rating Distribution\n",
        "***\n",
        "* **Objective:** Understand the overall landscape of customer feedback before feature engineering.\n",
        "* **What We Do:** Visualize the distribution of the `rating_review` column to identify patterns, skewness, or class imbalance.\n",
        "* **Why:** Provides a foundational understanding of the dataset and informs preprocessing and modeling decisions.\n",
        "* We will not be using `3` as it is neutral"
      ],
      "metadata": {
        "id": "XDiU9XstBzEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 2.1: Analyze Raw Star Rating Distribution ---\n",
        "print(\"--- 2.1: Analyzing the distribution of raw star ratings ---\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.countplot(x='rating_review', data=df_sample, palette='viridis')\n",
        "plt.title('Distribution of Customer Star Ratings', fontsize=16, weight='bold')\n",
        "plt.xlabel('Star Rating', fontsize=12)\n",
        "plt.ylabel('Number of Reviews', fontsize=12)\n",
        "\n",
        "# Add annotations to make the chart instantly readable\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():,}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
        "                textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dGCCDjQo-KpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights\n",
        "***\n",
        "* **Observation:** The distribution of ratings is strongly positively skewed. Most reviews are 5-star, while 1-2 star reviews are rare.\n",
        "* **Implications:**\n",
        "  - Customers are generally satisfied.\n",
        "  - Significant **class imbalance** exists for sentiment modeling: negative class is much smaller than positive class.\n",
        "* **Next Step:** Verify that the `sentiment` column correctly reflects business logic (1-2 stars = Negative, 4-5 stars = Positive) to ensure target variable integrity.\n",
        "* **Why It Matters:** Class imbalance can bias the model toward the majority class, affecting metrics like accuracy, F1-score, and AUC. We will need to account for this during preprocessing and evaluation.\n"
      ],
      "metadata": {
        "id": "WrxT-NxbC549"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Verifying the Sentiment Column\n",
        "***\n",
        "* **Objective:** Ensure the `sentiment` column aligns with our business logic for binary classification (1-2 stars = Negative, 4-5 stars = Positive).\n",
        "* **What We Do:** Check that the sentiment labels correctly reflect the rating values and calculate the proportion of positive vs negative reviews.\n",
        "* **Why:** Confirms the integrity of our target variable and quantifies the **class imbalance** we need to address during modeling.\n",
        "* **Next Step:** Based on this verification, decide on preprocessing strategies such as **resampling, class weighting, or stratified splitting** to handle imbalance effectively.\n"
      ],
      "metadata": {
        "id": "NLzyqSi1DUh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 2.2: Verify and Quantify Sentiment Class Distribution ---\n",
        "print(\"--- 2.2: Verifying the sentiment column distribution ---\")\n",
        "\n",
        "# Quantify the class imbalance in the 'sentiment' column\n",
        "print(\"\\nSentiment Class Distribution:\")\n",
        "sentiment_counts = df_sample['sentiment'].value_counts()\n",
        "print(sentiment_counts)\n",
        "print(f\"\\nNegative (0) reviews make up {sentiment_counts[0] / sentiment_counts.sum() * 100:.2f}% of the dataset.\")\n",
        "print(f\"Positive (1) reviews make up {sentiment_counts[1] / sentiment_counts.sum() * 100:.2f}% of the dataset.\")\n",
        "\n",
        "# Visualize the imbalance\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='coolwarm')\n",
        "plt.title('Sentiment Class Distribution (0=Negative, 1=Positive)', fontsize=16, weight='bold')\n",
        "plt.xlabel('Sentiment Class', fontsize=12)\n",
        "plt.ylabel('Number of Reviews', fontsize=12)\n",
        "plt.xticks(ticks=[0, 1], labels=['Negative', 'Positive'])\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():,}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
        "                textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HChmv1-hB2BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Insights\n",
        "***\n",
        "* **Observation:** The sentiment column correctly reflects our business logic, confirming the integrity of the target variable.\n",
        "* **Class Distribution:**\n",
        "  - Positive Reviews (1): 81,960\n",
        "  - Negative Reviews (0): 10,363\n",
        "* **Implications:**\n",
        "  - Positive class is ~8× larger than negative class.\n",
        "  - A naive model could achieve ~90% accuracy by always predicting \"positive\".\n",
        "  - We must **handle class imbalance** and use evaluation metrics robust to it, such as **F1-score** and **AUC**, instead of relying on accuracy alone.\n",
        "* **Next Step:** Implement preprocessing and modeling strategies that account for class imbalance.\n"
      ],
      "metadata": {
        "id": "hkisqBSyDs3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Reproducible Text Cleaning\n",
        "***\n",
        "* **Objective:** Create a clean, standardized text feature for modeling.\n",
        "* **What We Do:** Remove noise from raw text such as punctuation, capitalization, and common stopwords that add little predictive value.\n",
        "* **Why:** Ensures models focus on words that carry the most sentiment and allows the preprocessing to be **reproducible** across datasets.\n",
        "* **Next Step:** Apply this pipeline to generate the final `cleaned_review` column for feature engineering and modeling.\n"
      ],
      "metadata": {
        "id": "cbFmtsWqD2Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# --- 2.3: Re-running Text Preprocessing for Reproducibility ---\n",
        "print(\"--- 2.3: Re-running Text Preprocessing for Reproducibility ---\")\n",
        "\n",
        "# Ensure NLTK data is downloaded\n",
        "# We use a try/except block to check if data is present and only download if necessary\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "    nltk.data.find('corpora/omw-1.4')\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK data...\")\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('omw-1.4')\n",
        "else:\n",
        "    print(\"NLTK data already downloaded.\")\n",
        "\n",
        "\n",
        "# Initialize our tools\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# --- REMOVED: tqdm import and tqdm.pandas(desc=\"Cleaning Reviews\") ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"A robust function to clean and standardize text.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\" # Return empty string for non-string inputs (e.g., NaN)\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove special characters, numbers, and punctuation\n",
        "    words = text.split() # Tokenize (split into words)\n",
        "    # Lemmatize words to their root form and remove stopwords\n",
        "    cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(cleaned_words)\n",
        "\n",
        "# Re-create the 'cleaned_review' column\n",
        "# --- CRITICAL CHANGE: Changed .progress_apply() back to standard .apply() ---\n",
        "df_sample['cleaned_review'] = df_sample['review_text'].apply(preprocess_text)\n",
        "\n",
        "print(\"\\nText cleaning complete.\")\n",
        "print(\"A new 'cleaned_review' column has been created.\")\n",
        "print(\"\\nHere is a 'before and after' comparison:\")\n",
        "display(df_sample[['review_text', 'cleaned_review']].head())"
      ],
      "metadata": {
        "id": "GIzdT1_1DYS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Baseline Model: Logistic Regression**\n",
        "\n",
        "**Objective:** Establish a simple, interpretable benchmark before testing advanced models.  \n",
        "\n",
        "**Steps:**  \n",
        "- Initialize a **Logistic Regression** model with `class_weight='balanced'` to handle class imbalance.  \n",
        "- Train on **X_train_tfidf** and evaluate on **X_test_tfidf**.  \n",
        "- Generate a **classification report** and **confusion matrix** to assess performance.  \n",
        "\n",
        "**Why:**  \n",
        "A baseline helps measure if complex models truly add value. Logistic Regression is fast, efficient, and interpretable—ideal for gauging how well linear features capture sent\n"
      ],
      "metadata": {
        "id": "KuPNE-HY6q9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --- 4.1: Train and Evaluate the Baseline Logistic Regression Model ---\n",
        "print(\"--- 4.1: Training the baseline Logistic Regression model ---\")\n",
        "\n",
        "# Prepare data for modeling: TF-IDF Vectorization and Train-Test Split\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Consider top 5000 features\n",
        "\n",
        "# Fit and transform the 'cleaned_review' column\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_sample['cleaned_review'])\n",
        "y = df_sample['sentiment'] # Target variable\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y # Stratify to maintain sentiment distribution\n",
        ")\n",
        "\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_tfidf: {X_test_tfidf.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Initialize the model\n",
        "# class_weight='balanced' is crucial for handling our imbalanced dataset\n",
        "baseline_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
        "\n",
        "# 2. Train the model on the TF-IDF transformed training data\n",
        "baseline_model.fit(X_train_tfidf, y_train)\n",
        "print(\"Model training complete.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 3. Make predictions on the test set\n",
        "y_pred_baseline = baseline_model.predict(X_test_tfidf)\n",
        "\n",
        "# 4. Evaluate the model's performance\n",
        "print(\"Classification Report for Baseline Model:\")\n",
        "print(classification_report(y_test, y_pred_baseline, target_names=['Negative (0)', 'Positive (1)']))\n",
        "\n",
        "# 5. Display the confusion matrix for a visual evaluation\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred_baseline)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix - Baseline Model', fontsize=16)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xYhU7At1D8dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Advanced Model: Fine-Tuning DistilBERT**\n",
        "\n",
        "**Objective:**  \n",
        "Build a high-performance sentiment classifier using **DistilBERT**, a lightweight transformer model, to surpass the baseline — especially in identifying negative reviews more precisely.\n",
        "\n",
        "**Steps:**  \n",
        "- Format data using Hugging Face **Dataset** objects.  \n",
        "- Load **DistilBERT tokenizer** and convert text into token IDs.  \n",
        "- Load a **pre-trained DistilBERT model** for binary classification.  \n",
        "- Define **TrainingArguments** (epochs, batch size, learning rate, etc.).  \n",
        "- Initialize the **Trainer** and fine-tune on our dataset.  \n",
        "\n",
        "**Why:**  \n",
        "DistilBERT captures **semantic and contextual meaning** far beyond word frequency (TF-IDF). By fine-tuning it on Sephora reviews, we adapt its deep language understanding to **domain-specific sentiment**, potentially achieving **higher precision and overall robustness**."
      ],
      "metadata": {
        "id": "w6f_3LFJ7r-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Add this line to disable optional W&B logging and avoid interruptions ---\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset, disable_progress_bar # Import the function to disable progress bars\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# --- 5.1: Preparing Data and Fine-Tuning DistilBERT ---\n",
        "print(\"--- 5.1: Preparing data for the transformer model ---\")\n",
        "\n",
        "# We need to re-split the original text data, not the TF-IDF vectors\n",
        "X = df_sample['review_text'].astype(str) # Ensure text is string type\n",
        "y = df_sample['sentiment']\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create pandas DataFrames from the splits\n",
        "train_df = pd.DataFrame({'text': X_train_text.tolist(), 'label': y_train.tolist()})\n",
        "test_df = pd.DataFrame({'text': X_test_text.tolist(), 'label': y_test.tolist()})\n",
        "\n",
        "# Convert pandas DataFrames to Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Create a tokenization function\n",
        "def tokenize_function(examples):\n",
        "    # Truncate texts to the model's maximum supported length\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
        "\n",
        "# --- FIX 1: Disable the progress bars for the .map() function ---\n",
        "disable_progress_bar()\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "# Apply the tokenization to our datasets (this will now run silently)\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "\n",
        "print(\"\\n--- Starting DistilBERT fine-tuning ---\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    disable_tqdm=True, # --- FIX 2: Disables the Trainer's progress bars ---\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n--- Fine-tuning complete. Evaluating the model ---\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = trainer.predict(tokenized_test_dataset)\n",
        "y_pred_distilbert = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Display the classification report and confusion matrix\n",
        "print(\"\\nClassification Report for DistilBERT Model:\")\n",
        "print(classification_report(y_test, y_pred_distilbert, target_names=['Negative (0)', 'Positive (1)']))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm_distilbert = confusion_matrix(y_test, y_pred_distilbert)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_distilbert, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive']) # --- FIX 3: Corrected typo from 'ytickslabel' ---\n",
        "plt.title('Confusion Matrix - DistilBERT Model', fontsize=16)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQcg11PB7K0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Sanity Checks**"
      ],
      "metadata": {
        "id": "2c4WW2CkJpln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1 ROC & PR Curves for Negative Class**"
      ],
      "metadata": {
        "id": "DmGsxR1ayfI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "# --- 6.2: ROC & PR Curves for Negative Class ---\n",
        "# Get predicted probabilities for the negative class (class 0)\n",
        "y_probs = predictions.predictions[:, 0]  # probability scores for class 0\n",
        "\n",
        "# --- ROC Curve ---\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs, pos_label=0)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Negative Class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# --- Precision-Recall Curve ---\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_probs, pos_label=0)\n",
        "pr_auc = average_precision_score(y_test, y_probs, pos_label=0)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall, precision, color='purple', lw=2, label=f'PR curve (AP = {pr_auc:.3f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve - Negative Class')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yih793DL74bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2 Training vs. Validation Loss**"
      ],
      "metadata": {
        "id": "TvHacclFyp6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Sanity Check 2: Plotting Training vs. Validation Loss ---\n",
        "print(\"--- Plotting model loss curves ---\")\n",
        "\n",
        "# 1. Access the training history from the trainer object\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# 2. Separate the training and validation logs\n",
        "train_logs = [log for log in log_history if 'loss' in log]\n",
        "eval_logs = [log for log in log_history if 'eval_loss' in log]\n",
        "\n",
        "# 3. Create DataFrames for easier plotting\n",
        "df_train_loss = pd.DataFrame(train_logs)\n",
        "df_eval_loss = pd.DataFrame(eval_logs)\n",
        "\n",
        "# 4. Create the plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Plot the training loss as a line plot\n",
        "sns.lineplot(x='step', y='loss', data=df_train_loss, label='Training Loss', color='royalblue')\n",
        "\n",
        "# Plot the validation loss as a distinct point (since we have one per epoch)\n",
        "sns.scatterplot(x='step', y='eval_loss', data=df_eval_loss, label='Validation Loss', color='darkorange', s=150, zorder=5)\n",
        "\n",
        "# 5. Formatting\n",
        "plt.title('Training vs. Validation Loss', fontsize=16, weight='bold')\n",
        "plt.xlabel('Training Steps', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uKZY46QOIxXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3 Prediction Probabilities**"
      ],
      "metadata": {
        "id": "7_JobEkRy3ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.special import softmax\n",
        "\n",
        "# --- Sanity Check 1: Analyzing Prediction Probabilities ---\n",
        "print(\"--- Analyzing model prediction confidence ---\")\n",
        "\n",
        "# 1. Get the raw logits from the prediction output\n",
        "# The .predictions attribute contains the logits\n",
        "logits = predictions.predictions\n",
        "\n",
        "# 2. Convert logits to probabilities using the softmax function\n",
        "# axis=1 ensures softmax is applied across the two class outputs for each review\n",
        "probs = softmax(logits, axis=1)\n",
        "\n",
        "# 3. Create a detailed analysis DataFrame\n",
        "analysis_df = pd.DataFrame({\n",
        "    'text': X_test_text,\n",
        "    'true_label': y_test,\n",
        "    'predicted_label': y_pred_distilbert,\n",
        "    'prob_negative(0)': probs[:, 0], # Probability of being negative\n",
        "    'prob_positive(1)': probs[:, 1]  # Probability of being positive\n",
        "})\n",
        "analysis_df['is_correct'] = (analysis_df['true_label'] == analysis_df['predicted_label'])\n",
        "\n",
        "print(f\"Created analysis DataFrame with {len(analysis_df)} test samples.\")\n",
        "print(\"\\n--- Model's Most Confident Mistakes (Incorrect Predictions with >90% Confidence) ---\")\n",
        "\n",
        "# Filter for incorrect predictions where the model was highly confident\n",
        "confident_mistakes = analysis_df[\n",
        "    (analysis_df['is_correct'] == False) &\n",
        "    ((analysis_df['prob_negative(0)'] > 0.90) | (analysis_df['prob_positive(1)'] > 0.90))\n",
        "]\n",
        "\n",
        "# Set display options to see full text\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Display the top 5 most confident mistakes\n",
        "display(confident_mistakes.head())"
      ],
      "metadata": {
        "id": "roDZt-rmJ_Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.4 Changing random state value**"
      ],
      "metadata": {
        "id": "6imq4azPL8pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Ensure you have 'DistilBertForSequenceClassification' as the correct import\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results_v2',\n",
        "    num_train_epochs=3, # Example value\n",
        "    per_device_train_batch_size=8, # Example value\n",
        "    per_device_eval_batch_size=8, # Example value\n",
        "    warmup_steps=500, # Example value\n",
        "    weight_decay=0.01, # Example value\n",
        "    logging_dir='./logs_v2',\n",
        "    logging_steps=100,\n",
        "    # --- CRITICAL CHANGE: This line disables the tqdm progress bar ---\n",
        "    disable_tqdm=True,\n",
        "    # --------------------------------------------------------------------\n",
        ")\n",
        "\n",
        "\n",
        "# --- Sanity Check: Retraining on a New Data Split ---\n",
        "print(\"--- Starting Sanity Check: Retraining on a New Data Split ---\")\n",
        "\n",
        "# 1. Perform a new train-test split with a different random_state\n",
        "print(\"\\nStep 1: Performing new 80/20 data split with random_state=2025...\")\n",
        "X = df_sample['review_text'].astype(str)\n",
        "y = df_sample['sentiment']\n",
        "\n",
        "X_train_text_v2, X_test_text_v2, y_train_v2, y_test_v2 = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=2025, # Using a new seed for a different split\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 2. Convert the new splits into Hugging Face Dataset objects\n",
        "print(\"Step 2: Converting new splits to Hugging Face Dataset objects...\")\n",
        "train_df_v2 = pd.DataFrame({'text': X_train_text_v2.tolist(), 'label': y_train_v2.tolist()})\n",
        "test_df_v2 = pd.DataFrame({'text': X_test_text_v2.tolist(), 'label': y_test_v2.tolist()})\n",
        "\n",
        "train_dataset_v2 = Dataset.from_pandas(train_df_v2)\n",
        "test_dataset_v2 = Dataset.from_pandas(test_df_v2)\n",
        "\n",
        "# Tokenize the new datasets\n",
        "# We can reuse the tokenizer and tokenize_function from the previous step\n",
        "tokenized_train_dataset_v2 = train_dataset_v2.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset_v2 = test_dataset_v2.map(tokenize_function, batched=True)\n",
        "\n",
        "# 3. CRITICAL: Re-initialize the model to reset its weights\n",
        "print(\"Step 3: Re-initializing DistilBERT model from pre-trained weights...\")\n",
        "model_v2 = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "\n",
        "# 4. Re-initialize the Trainer with the new model and datasets\n",
        "# We use the 'training_args' defined above with disable_tqdm=True\n",
        "print(\"Step 4: Re-initializing the Trainer...\")\n",
        "trainer_v2 = Trainer(\n",
        "    model=model_v2,\n",
        "    args=training_args, # This now correctly passes the arguments\n",
        "    train_dataset=tokenized_train_dataset_v2,\n",
        "    eval_dataset=tokenized_test_dataset_v2,\n",
        ")\n",
        "\n",
        "# 5. Start the new training run (without tqdm progress bars)\n",
        "print(\"\\nStep 5: Starting training on the new data split. This will take 15-30 minutes...\")\n",
        "trainer_v2.train()\n",
        "\n",
        "# 6. Evaluate on the new test set\n",
        "print(\"\\n--- Sanity Check Training Complete. Evaluating... ---\")\n",
        "predictions_v2 = trainer_v2.predict(tokenized_test_dataset_v2)\n",
        "y_pred_distilbert_v2 = np.argmax(predictions_v2.predictions, axis=1)\n",
        "\n",
        "# 7. Display the new classification report\n",
        "print(\"\\nClassification Report for Sanity Check Model (random_state=2025):\")\n",
        "print(classification_report(y_test_v2, y_pred_distilbert_v2, target_names=['Negative (0)', 'Positive (1)']))"
      ],
      "metadata": {
        "id": "saUQFe5jKooD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DOBBY IS FREE!**"
      ],
      "metadata": {
        "id": "C6YC_1C7Ubdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Deep Dive Into Insights**\n",
        "### **7.1 Disproving the \"Price = Quality\" Myth**\n",
        "**Objective:** To empirically test the common assumption that higher-priced products receive better customer ratings.\n",
        "\n",
        "**What We Do:**  \n",
        "We segment products into distinct price tiers (Budget, Mid-Range, Luxury, Ultra-Luxury) and visualize the distribution of customer ratings within each tier using a **violin plot**. This approach shows the full spread of ratings, including the median, concentration, and outliers, which is more informative than just looking at averages.\n",
        "\n",
        "**Why:**  \n",
        "This analysis directly challenges a core marketing assumption. If price does not correlate strongly with customer satisfaction, it fundamentally changes how products should be positioned, marketed, and valued.\n"
      ],
      "metadata": {
        "id": "p8MGyQ84UmMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Deep Dive 1: Price Tier Performance Analysis ---\n",
        "print(\"--- Analyzing Product Performance by Price Tier ---\")\n",
        "\n",
        "# 1. Create a DataFrame for this analysis\n",
        "price_tier_df = df_sample.copy().dropna(subset=['price_usd', 'rating_review'])\n",
        "\n",
        "# 2. Engineer price tiers using pd.cut\n",
        "bins = [0, 25, 75, 150, 1000] # Added an Ultra-Luxury tier for more granularity\n",
        "labels = ['Budget (<$25)', 'Mid-Range ($25-$75)', 'Luxury ($75-$150)', 'Ultra-Luxury (>$150)']\n",
        "price_tier_df['price_tier'] = pd.cut(price_tier_df['price_usd'], bins=bins, labels=labels, right=False)\n",
        "price_tier_df.dropna(subset=['price_tier'], inplace=True)\n",
        "\n",
        "print(\"Segmented products into four price tiers.\")\n",
        "\n",
        "# 3. Create the visualization\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.violinplot(\n",
        "    x='price_tier',\n",
        "    y='rating_review',\n",
        "    data=price_tier_df,\n",
        "    palette='viridis',\n",
        "    inner='quartile' # Shows the median and interquartile range\n",
        ")\n",
        "plt.title('Distribution of Customer Ratings by Price Tier', fontsize=18, weight='bold')\n",
        "plt.xlabel('Price Tier', fontsize=12)\n",
        "plt.ylabel('Rating (1-5)', fontsize=12)\n",
        "plt.ylim(0.5, 5.5) # Set y-axis to the rating scale\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tMTKBeqxMhCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2 Quantifying the Financial Cost of Unsolved Customer Problems**\n",
        "**Objective:**  \n",
        "To estimate the potential revenue loss associated with recurring product issues reported by customers, helping prioritize problem-solving efforts for maximum business impact.\n",
        "\n",
        "**What We Do:**  \n",
        "We define key customer problem cohorts (e.g., acne, wrinkle, dryness, pore issues) and calculate the **Revenue at Risk** for each cohort. This is done by multiplying the total revenue of products reviewed by the cohort with the 1-star review rate. Finally, we visualize the results with a bar chart to clearly highlight which problems pose the greatest financial risk.\n",
        "\n",
        "**Why:**  \n",
        "This analysis allows the business to identify the most financially impactful unresolved issues. By focusing on problems that cost the most in terms of potential lost revenue, product teams can prioritize improvements, reduce negative customer experiences, and protect revenue.\n"
      ],
      "metadata": {
        "id": "SibVicAcWhwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.3 Risk Matrix**"
      ],
      "metadata": {
        "id": "Ah4WENRmxDRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, ensure the library for non-overlapping text is installed\n",
        "!pip install -q adjustText\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from adjustText import adjust_text\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# --- Deep Dive 3 (Final Polish): The Executive-Ready Risk Matrix ---\n",
        "print(\"--- Building the Final Executive-Ready Strategic Risk Matrix ---\")\n",
        "\n",
        "# 1. Use the 'risk_df' DataFrame with quadrants already assigned\n",
        "risk_df = risk_df.copy()\n",
        "\n",
        "# 2. Define quadrant boundaries\n",
        "median_likelihood = risk_df['likelihood_of_failure'].median()\n",
        "median_impact = risk_df['financial_impact'].median()\n",
        "\n",
        "# 3. Create the plot\n",
        "fig, ax = plt.subplots(figsize=(20, 15))\n",
        "\n",
        "# Define our color palette\n",
        "palette = {\n",
        "    'Critical Priority': 'firebrick',\n",
        "    'Product Quality Issue': 'darkorange',\n",
        "    'Protect the Stars': 'forestgreen',\n",
        "    'Low Priority': 'darkgray'\n",
        "}\n",
        "\n",
        "# 4. Create the scatter plot with size mapping but NO automatic legend\n",
        "sns.scatterplot(\n",
        "    x='financial_impact',\n",
        "    y='likelihood_of_failure',\n",
        "    data=risk_df,\n",
        "    hue='quadrant',\n",
        "    palette=palette,\n",
        "    size='financial_impact',\n",
        "    sizes=(50, 2000),\n",
        "    alpha=0.7,\n",
        "    ax=ax,\n",
        "    legend=False # Turn off the default, cluttered legend\n",
        ")\n",
        "\n",
        "# Use a log scale for better distribution\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# 5. Add intelligent labels for the most critical products\n",
        "texts = []\n",
        "products_to_label = pd.concat([\n",
        "    risk_df[risk_df['quadrant'] == 'Critical Priority'].nlargest(5, 'financial_impact'),\n",
        "    risk_df[risk_df['quadrant'] == 'Protect the Stars'].nlargest(5, 'financial_impact')\n",
        "])\n",
        "\n",
        "for i, row in products_to_label.iterrows():\n",
        "    texts.append(ax.text(row['financial_impact'], row['likelihood_of_failure'], row['product_name'], fontsize=12))\n",
        "\n",
        "# Use adjust_text to prevent labels from overlapping\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle=\"-\", color='black', lw=0.5))\n",
        "\n",
        "# 6. Add a CLEAN, MANUAL legend\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], marker='o', color='w', label='Critical Priority', markerfacecolor='firebrick', markersize=15),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Product Quality Issue', markerfacecolor='darkorange', markersize=15),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Protect the Stars', markerfacecolor='forestgreen', markersize=15),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Low Priority', markerfacecolor='darkgray', markersize=15),\n",
        "    Line2D([], [], color='black', linestyle='--', label=f'Median Impact (${median_impact:,.0f})'),\n",
        "    Line2D([], [], color='black', linestyle='--', label=f'Median Likelihood ({median_likelihood:.1f}%)')\n",
        "]\n",
        "ax.legend(handles=legend_elements, title='Quadrant', loc='upper right', fontsize=14, title_fontsize=16)\n",
        "\n",
        "# Add a text annotation to explain size\n",
        "ax.text(0.02, 0.95, 'Dot size represents\\nFinancial Impact', transform=ax.transAxes, fontsize=14,\n",
        "        verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', alpha=0.5))\n",
        "\n",
        "\n",
        "# 7. Final Formatting\n",
        "ax.axvline(x=median_impact, color='black', linestyle='--')\n",
        "ax.axhline(y=median_likelihood, color='black', linestyle='--')\n",
        "ax.set_title('Executive Risk Matrix: Product Failure vs. Financial Impact', fontsize=28, weight='bold', pad=20)\n",
        "ax.set_xlabel('Financial Impact (Estimated Revenue) - Log Scale', fontsize=16)\n",
        "ax.set_ylabel('Likelihood of Failure (1-Star Review Rate %)', fontsize=16)\n",
        "ax.grid(which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q3XnvYG5WGeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# --- The Strategic Heatmap ---\n",
        "print(\"--- Building the Strategic Heatmap ---\")\n",
        "\n",
        "# 1. Use the 'risk_df' from the previous step\n",
        "risk_df_hm = risk_df.copy()\n",
        "# Calculate 'revenue_at_risk' for the heatmap values\n",
        "risk_df_hm['revenue_at_risk'] = risk_df_hm['financial_impact'] * (risk_df_hm['likelihood_of_failure'] / 100)\n",
        "\n",
        "# 2. Create bins for our axes\n",
        "# Bins for Likelihood of Failure (1-Star Rate %)\n",
        "likelihood_bins = [0, 2.5, 5, 10, 100]\n",
        "likelihood_labels = ['Low Risk (<2.5%)', 'Medium Risk (2.5-5%)', 'High Risk (5-10%)', 'Critical Risk (>10%)']\n",
        "risk_df_hm['risk_tier'] = pd.cut(risk_df_hm['likelihood_of_failure'], bins=likelihood_bins, labels=likelihood_labels, right=False)\n",
        "\n",
        "# Bins for Financial Impact (Estimated Revenue)\n",
        "impact_bins = [0, 2500, 10000, 100000]\n",
        "impact_labels = ['Niche Product (<$2.5k)', 'Core Product ($2.5k-$10k)', 'Bestseller (>$10k)']\n",
        "risk_df_hm['impact_tier'] = pd.cut(risk_df_hm['financial_impact'], bins=impact_bins, labels=impact_labels, right=False)\n",
        "\n",
        "# 3. Create the pivot table for the heatmap\n",
        "# The value in each cell will be the SUM of all 'revenue_at_risk' in that bin\n",
        "heatmap_data = risk_df_hm.pivot_table(\n",
        "    values='revenue_at_risk',\n",
        "    index='risk_tier',\n",
        "    columns='impact_tier',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0 # Fill empty cells with 0\n",
        ")\n",
        "heatmap_data = heatmap_data.reindex(index=likelihood_labels[::-1]) # Reverse index for intuitive top-down view\n",
        "\n",
        "# 4. Visualize the Heatmap\n",
        "plt.figure(figsize=(16, 10))\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    annot=True, # Show the values in each cell\n",
        "    fmt=\",.0f\", # Format as currency with no decimals\n",
        "    cmap='Reds', # Use a red color scale to signify risk\n",
        "    linewidths=.5,\n",
        "    annot_kws={\"size\": 14} # Make annotations readable\n",
        ")\n",
        "\n",
        "plt.title('Strategic Risk Heatmap: Total Revenue at Risk by Category', fontsize=24, weight='bold', pad=20)\n",
        "plt.ylabel('Likelihood of Failure', fontsize=14)\n",
        "plt.xlabel('Financial Impact', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# 5. Create the Actionable \"Hit List\"\n",
        "print(\"\\n--- Actionable Hit List: Top Offenders in Highest Risk Categories ---\")\n",
        "# Find the highest risk cell\n",
        "highest_risk_cell = risk_df_hm[\n",
        "    (risk_df_hm['risk_tier'] == 'Critical Risk (>10%)') &\n",
        "    (risk_df_hm['impact_tier'] == 'Bestseller (>$10k)')\n",
        "]\n",
        "\n",
        "print(\"Products in the 'Critical Risk / Bestseller' Quadrant:\")\n",
        "display(highest_risk_cell[['product_name', 'revenue_at_risk']].nlargest(5, 'revenue_at_risk'))"
      ],
      "metadata": {
        "id": "tAX-pn5gYjmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.4 Impact of Key Ingredients on Ratings**"
      ],
      "metadata": {
        "id": "6tV7b0z4kC6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Deep Dive 1: Ingredient-Sentiment Correlation ---\n",
        "print(\"--- Analyzing the Impact of Key Ingredients on Ratings ---\")\n",
        "\n",
        "# 1. Isolate Moisturizers & Clean Ingredient Data\n",
        "ingredient_df = df_sample[df_sample['product_name'].str.contains('Moisturizer', case=False, na=False)].copy()\n",
        "ingredient_df.dropna(subset=['review_text', 'rating_review'], inplace=True) # Using review_text as a proxy for ingredient list presence in this sample\n",
        "ingredient_df['cleaned_review_lower'] = ingredient_df['cleaned_review'].str.lower()\n",
        "\n",
        "# 2. Feature Engineering for Key Ingredients\n",
        "hero_ingredients = ['squalane', 'ceramide', 'hyaluronic acid']\n",
        "controversial_ingredients = ['fragrance', 'alcohol']\n",
        "\n",
        "ingredients_to_check = hero_ingredients + controversial_ingredients\n",
        "for ingredient in ingredients_to_check:\n",
        "    col_name = f'has_{ingredient.replace(\" \", \"_\")}'\n",
        "    ingredient_df[col_name] = ingredient_df['cleaned_review_lower'].str.contains(ingredient, na=False)\n",
        "\n",
        "# 3. Analyze and Visualize the Impact on Ratings\n",
        "ingredient_impact = {}\n",
        "for ingredient in ingredients_to_check:\n",
        "    col_name = f'has_{ingredient.replace(\" \", \"_\")}'\n",
        "    mean_with = ingredient_df[ingredient_df[col_name] == True]['rating_review'].mean()\n",
        "    mean_without = ingredient_df[ingredient_df[col_name] == False]['rating_review'].mean()\n",
        "    if pd.notna(mean_with) and pd.notna(mean_without):\n",
        "        ingredient_impact[ingredient] = mean_with - mean_without\n",
        "\n",
        "impact_df = pd.DataFrame(list(ingredient_impact.items()), columns=['Ingredient', 'Rating_Change'])\n",
        "impact_df = impact_df.sort_values('Rating_Change', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='Rating_Change', y='Ingredient', data=impact_df, palette=\"coolwarm_r\")\n",
        "plt.title('Impact of Key Ingredients on Average Moisturizer Rating', fontsize=18, weight='bold')\n",
        "plt.xlabel('Change in Average Rating (With vs. Without Ingredient)', fontsize=12)\n",
        "plt.ylabel('Ingredient', fontsize=12)\n",
        "plt.axvline(x=0, color='black', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jz3SmfswZjhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "###**7.5 Moisturizer Ratings by Customer Skin Type**"
      ],
      "metadata": {
        "id": "2YognkBphqZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Deep Dive 2: Product-Market Fit in Moisturizers ---\n",
        "print(\"--- Analyzing Moisturizer Performance Across Skin Types ---\")\n",
        "\n",
        "# 1. Isolate Moisturizers and standardize skin types\n",
        "moisturizer_df = df_sample[df_sample['product_name'].str.contains('Moisturizer', case=False, na=False)].copy()\n",
        "moisturizer_df.dropna(subset=['skin_type', 'rating_review'], inplace=True)\n",
        "moisturizer_df['skin_type'] = moisturizer_df['skin_type'].str.lower().str.strip()\n",
        "target_skin_types = ['dry', 'oily', 'combination', 'normal']\n",
        "moisturizer_df = moisturizer_df[moisturizer_df['skin_type'].isin(target_skin_types)]\n",
        "\n",
        "# 2. Focus on the most-reviewed products for impact\n",
        "top_products = moisturizer_df['product_name'].value_counts().nlargest(15).index\n",
        "analysis_df = moisturizer_df[moisturizer_df['product_name'].isin(top_products)]\n",
        "\n",
        "# 3. Pivot the data to create the heatmap\n",
        "heatmap_data = analysis_df.pivot_table(index='product_name', columns='skin_type', values='rating_review', aggfunc='mean')\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=.5, vmin=3.5, vmax=5)\n",
        "plt.title('Moisturizer Ratings by Customer Skin Type', fontsize=18, weight='bold')\n",
        "plt.xlabel('Customer Skin Type', fontsize=12)\n",
        "plt.ylabel('Moisturizer Product', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E47b2C1rfocP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Key Insight:**  \n",
        "- The heatmap shows that **one size does not fit all**.  \n",
        "- Clear *product–market fit mismatches* exist — e.g., **Original Skin Matte Moisturizer** performs well for **oily skin (4.83⭐)** but poorly for **dry skin (4.39⭐)**.  \n",
        "- Such gaps directly drive **avoidable negative reviews**.\n",
        "\n",
        "**Strategic Solution:**  \n",
        "- **Personalization & Marketing teams** should refine the **recommendation engine**.  \n",
        "- Promote **matte moisturizers** to *oily-skin* users and **hydrating products** to *dry-skin* users.  \n",
        "- A **data-driven targeting approach** that reduces dissatisfaction **without changing product formulas**.\n"
      ],
      "metadata": {
        "id": "Eoq628rHlTvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.6 What Makes a Review \"Helpful\"?**"
      ],
      "metadata": {
        "id": "t8gc1Sn1h0VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Deep Dive 3: Uncovering the DNA of a \"Helpful\" Review ---\n",
        "print(\"--- Analyzing What Makes a Review 'Helpful' ---\")\n",
        "\n",
        "# 1. Feature Engineering\n",
        "helpful_df = df_sample.copy().dropna(subset=['helpfulness', 'review_text'])\n",
        "helpful_df['review_length'] = helpful_df['review_text'].str.len()\n",
        "helpful_df['has_title'] = ~helpful_df['review_title'].isnull()\n",
        "bins = [0, 250, 500, 1000, 10000]\n",
        "labels = ['Short (<250)', 'Medium (250-500)', 'Long (500-1k)', 'Very Long (>1k)']\n",
        "helpful_df['length_bin'] = pd.cut(helpful_df['review_length'], bins=bins, labels=labels)\n",
        "helpful_df['sentiment_type'] = helpful_df['sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
        "\n",
        "# 2. Create Side-by-Side Visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(22, 8))\n",
        "fig.suptitle('What Makes a Review \"Helpful\"?', fontsize=20, weight='bold')\n",
        "\n",
        "# Plot 1: Impact of Title and Sentiment\n",
        "sns.barplot(x='sentiment_type', y='helpfulness', hue='has_title', data=helpful_df, ax=axes[0], palette={True: \"mediumpurple\", False: \"lightgray\"})\n",
        "axes[0].set_title('Helpfulness by Sentiment and Title Presence', fontsize=16)\n",
        "axes[0].set_xlabel('Review Sentiment', fontsize=12)\n",
        "axes[0].set_ylabel('Average Helpfulness Score', fontsize=12)\n",
        "\n",
        "# Plot 2: Impact of Review Length\n",
        "sns.pointplot(x='length_bin', y='helpfulness', data=helpful_df, ax=axes[1], color='teal', errorbar='sd')\n",
        "axes[1].set_title('Helpfulness by Review Length', fontsize=16)\n",
        "axes[1].set_xlabel('Review Length (Characters)', fontsize=12)\n",
        "axes[1].set_ylabel('Average Helpfulness Score', fontsize=12)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v7x-noPlhv5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight:**  \n",
        "Detail and structure are the strongest predictors of a helpful review. Longer, more descriptive reviews, and those that include a clear title, are consistently rated as more helpful by other shoppers.\n",
        "\n",
        "**Strategic Solution:**  \n",
        "This finding translates directly into an actionable UI/UX improvement. The review submission form should be redesigned to **encourage depth and structure**:\n",
        "- Make the *“Review Title”* field more prominent or required.  \n",
        "- Add a friendly prompt like *“More detail helps other shoppers!”* when users write short reviews.  \n",
        "\n",
        "These small, data-backed design enhancements can significantly improve the quality and perceived value of user-generated content across the platform.\n"
      ],
      "metadata": {
        "id": "K-NtrSgWkn7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.7 Common Phrases by Product Price Tier**\n"
      ],
      "metadata": {
        "id": "4iaSz2wIh40S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# --- Deep Dive 4: Price-Value Perception Analysis ---\n",
        "print(\"--- Analyzing Common Phrases by Product Price Tier ---\")\n",
        "\n",
        "# 1. Feature Engineering for Price Tiers\n",
        "price_df = df_sample.copy().dropna(subset=['price_usd', 'cleaned_review'])\n",
        "bins = [0, 25, 75, 500]\n",
        "labels = ['Budget (<$25)', 'Mid-Range ($25-$75)', 'Luxury (>$75)']\n",
        "price_df['price_tier'] = pd.cut(price_df['price_usd'], bins=bins, labels=labels, right=False)\n",
        "price_df.dropna(subset=['price_tier'], inplace=True)\n",
        "\n",
        "# 2. Text Cleaning & N-gram Extraction Function\n",
        "stop_words.update([\"product\", \"skin\", \"sephora\", \"like\", \"use\", \"get\", \"one\", \"make\", \"feel\"]) # Add more noise words\n",
        "\n",
        "def get_top_ngrams(corpus, n=15, ngram_range=(2, 3)):\n",
        "    vec = CountVectorizer(ngram_range=ngram_range, stop_words=list(stop_words)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    return sorted(words_freq, key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "# 3. Analyze Each Price Tier and Visualize\n",
        "fig, axes = plt.subplots(3, 1, figsize=(16, 24))\n",
        "fig.suptitle('Top Phrases by Product Price Tier', fontsize=20, weight='bold')\n",
        "\n",
        "for i, tier in enumerate(labels):\n",
        "    tier_text = price_df[price_df['price_tier'] == tier]['cleaned_review']\n",
        "    top_phrases = get_top_ngrams(tier_text)\n",
        "    df_phrases = pd.DataFrame(top_phrases, columns=['Phrase', 'Frequency'])\n",
        "    sns.barplot(x='Frequency', y='Phrase', data=df_phrases, ax=axes[i], palette='viridis')\n",
        "    axes[i].set_title(f'Most Common Phrases for {tier} Products', fontsize=16)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B8SQDFNPh1nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How Product Language Changes Across Price Tiers**\n",
        "\n",
        "**Key Insight:**  \n",
        "The language customers use reveals that they value **fundamentally different things** at each price point.  \n",
        "- **Budget shoppers** focus on simple, functional items (*“lip balm”*).  \n",
        "- **Mid-Range shoppers** emphasize solving specific problems (*“eye cream,” “acne prone”*).  \n",
        "- **Luxury shoppers** highlight high-level, results-driven concerns (*“fine lines,” “dark spots”*).\n",
        "\n",
        "**Strategic Solution:**  \n",
        "Marketing and Brand teams must **tailor their language to match customer expectations**.  \n",
        "- For **Luxury products**, messaging should emphasize *efficacy, sophistication, and visible results*.  \n",
        "- For **Budget products**, focus on *simplicity, reliability, and daily usability*.  \n",
        "\n"
      ],
      "metadata": {
        "id": "zxReHiuslFxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.8 Brand Performance**"
      ],
      "metadata": {
        "id": "UJ4jH4NTqW-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Highest & Lowest Rated Brands (Corrected for Uniformity) ---\n",
        "print(\"--- Analyzing Highest & Lowest Rated Brands with Uniform Scales ---\")\n",
        "\n",
        "# 1. Aggregate data\n",
        "brand_performance = df_sample.groupby('brand_name').agg(\n",
        "    avg_rating=('rating_review', 'mean'),\n",
        "    review_count=('rating_review', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# 2. Filter for significant brands\n",
        "significant_brands = brand_performance[brand_performance['review_count'] >= 300].copy()\n",
        "\n",
        "# 3. Get top/bottom 10 and then sort them both descending for uniformity\n",
        "top_10_brands = significant_brands.nlargest(10, 'avg_rating').sort_values('avg_rating', ascending=False)\n",
        "bottom_10_brands = significant_brands.nsmallest(10, 'avg_rating').sort_values('avg_rating', ascending=False)\n",
        "\n",
        "# 4. Visualize with uniform scales\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "fig.suptitle('Brand Performance: Highest vs. Lowest Rated (≥300 Reviews)', fontsize=20, weight='bold')\n",
        "\n",
        "# Plot Top 10 Highest Rated Brands\n",
        "sns.barplot(x='avg_rating', y='brand_name', data=top_10_brands, ax=axes[0], palette='Greens_r')\n",
        "axes[0].set_title('Top 10 Highest Rated Brands', fontsize=16)\n",
        "axes[0].set_xlabel('Average Star Rating', fontsize=12)\n",
        "axes[0].set_ylabel('Brand', fontsize=12)\n",
        "axes[0].set_xlim(3.5, 5) # Set uniform scale\n",
        "\n",
        "# Plot Bottom 10 Lowest Rated Brands\n",
        "sns.barplot(x='avg_rating', y='brand_name', data=bottom_10_brands, ax=axes[1], palette='Reds_r')\n",
        "axes[1].set_title('Bottom 10 Lowest Rated Brands', fontsize=16)\n",
        "axes[1].set_xlabel('Average Star Rating', fontsize=12)\n",
        "axes[1].set_ylabel('') # Hide y-label\n",
        "axes[1].set_xlim(3.5, 5) # Set uniform scale\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pnJhCEneh6PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.9 Product Performance**"
      ],
      "metadata": {
        "id": "t2Yny7B3qQ0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Highest & Lowest Rated Products (Corrected for Uniformity) ---\n",
        "print(\"--- Analyzing Highest & Lowest Rated Products with Uniform Scales ---\")\n",
        "\n",
        "# 1. Aggregate data\n",
        "product_performance = df_sample.groupby('product_name').agg(\n",
        "    avg_rating=('rating_review', 'mean'),\n",
        "    review_count=('rating_review', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# 2. Filter for significant products\n",
        "significant_products = product_performance[product_performance['review_count'] >= 100].copy()\n",
        "\n",
        "# 3. Get top/bottom 10 and sort them both descending\n",
        "top_10_products = significant_products.nlargest(10, 'avg_rating').sort_values('avg_rating', ascending=False)\n",
        "bottom_10_products = significant_products.nsmallest(10, 'avg_rating').sort_values('avg_rating', ascending=False)\n",
        "\n",
        "# 4. Visualize with uniform scales\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "fig.suptitle('Product Performance: Highest vs. Lowest Rated (≥100 Reviews)', fontsize=20, weight='bold')\n",
        "\n",
        "# Plot Top 10 Highest Rated Products\n",
        "sns.barplot(x='avg_rating', y='product_name', data=top_10_products, ax=axes[0], palette='Greens_r')\n",
        "axes[0].set_title('Top 10 Highest Rated Products', fontsize=16)\n",
        "axes[0].set_xlabel('Average Star Rating', fontsize=12)\n",
        "axes[0].set_ylabel('Product', fontsize=12)\n",
        "axes[0].set_xlim(3, 5) # Set uniform scale\n",
        "\n",
        "# Plot Bottom 10 Lowest Rated Products\n",
        "sns.barplot(x='avg_rating', y='product_name', data=bottom_10_products, ax=axes[1], palette='Reds_r')\n",
        "axes[1].set_title('Bottom 10 Lowest Rated Products', fontsize=16)\n",
        "axes[1].set_xlabel('Average Star Rating', fontsize=12)\n",
        "axes[1].set_ylabel('') # Hide y-label\n",
        "axes[1].set_xlim(3, 5) # Set uniform scale\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "abzMZeTMo1kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.10 Top 5 Segment Failures & Universal Underperformers**\n",
        "\n",
        "This is the most strategic analysis. It moves beyond simply identifying \"bad\" products and diagnoses why they are failing. It creates a direct, actionable \"hit list\" for two different departments: Marketing/Personalization (for Segment Failures) and R&D/Quality Control (for Universal Underperformers). This is the analysis that leads to the smartest, most targeted interventions."
      ],
      "metadata": {
        "id": "tRjIWD-rrXUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# --- Analysis 1: Identifying Top Strategic Failures ---\n",
        "print(\"--- Identifying Top 5 'Segment Failures' and 'Universal Underperformers' ---\")\n",
        "\n",
        "# 1. Calculate Rating Variance (Mismatch Metric)\n",
        "# We need to isolate a category with skin_type data, like Skincare\n",
        "skincare_df = df_sample[df_sample['primary_category'] == 'Skincare'].copy()\n",
        "skincare_df.dropna(subset=['skin_type', 'rating_review'], inplace=True)\n",
        "skincare_df['skin_type'] = skincare_df['skin_type'].str.lower().str.strip()\n",
        "common_skin_types = ['combination', 'dry', 'normal', 'oily']\n",
        "skincare_df = skincare_df[skincare_df['skin_type'].isin(common_skin_types)]\n",
        "\n",
        "segment_ratings = skincare_df.groupby(['product_name', 'skin_type'])['rating_review'].mean().unstack()\n",
        "rating_variance = segment_ratings.std(axis=1).reset_index(name='rating_variance')\n",
        "\n",
        "# 2. Calculate Revenue at Risk (Financial Risk Metric)\n",
        "skincare_df['is_1_star'] = skincare_df['rating_review'] == 1\n",
        "product_agg = skincare_df.groupby('product_name').agg(\n",
        "    total_reviews=('product_name', 'count'),\n",
        "    total_1_star=('is_1_star', 'sum'),\n",
        "    price_usd=('price_usd', 'first')\n",
        ").reset_index()\n",
        "significant_products = product_agg[product_agg['total_reviews'] >= 50].copy()\n",
        "significant_products['return_risk_pct'] = (significant_products['total_1_star'] / significant_products['total_reviews']) * 100\n",
        "significant_products['estimated_revenue'] = significant_products['total_reviews'] * significant_products['price_usd']\n",
        "significant_products['revenue_at_risk'] = significant_products['estimated_revenue'] * (significant_products['return_risk_pct'] / 100)\n",
        "\n",
        "# 3. Merge and Define Quadrants\n",
        "strategic_df = pd.merge(significant_products, rating_variance, on='product_name')\n",
        "strategic_df.dropna(subset=['revenue_at_risk', 'rating_variance'], inplace=True)\n",
        "median_risk = strategic_df['revenue_at_risk'].median()\n",
        "median_variance = strategic_df['rating_variance'].median()\n",
        "\n",
        "segment_failures = strategic_df[(strategic_df['revenue_at_risk'] >= median_risk) & (strategic_df['rating_variance'] >= median_variance)]\n",
        "universal_underperformers = strategic_df[(strategic_df['revenue_at_risk'] >= median_risk) & (strategic_df['rating_variance'] < median_variance)]\n",
        "\n",
        "# 4. Get the hit lists and visualize\n",
        "top_segment_failures = segment_failures.nlargest(5, 'revenue_at_risk')\n",
        "top_universal_underperformers = universal_underperformers.nlargest(5, 'revenue_at_risk')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "fig.suptitle('Prioritized Action List: Top Products Driving Financial Risk', fontsize=20, weight='bold')\n",
        "\n",
        "sns.barplot(x='revenue_at_risk', y='product_name', data=top_segment_failures, ax=axes[0], palette='Oranges_r')\n",
        "axes[0].set_title('Top 5 \"Segment Failures\" (Marketing/Personalization Issue)', fontsize=16)\n",
        "axes[0].set_xlabel('Financial Risk (Revenue at Risk)', fontsize=12)\n",
        "axes[0].set_ylabel('Product', fontsize=12)\n",
        "\n",
        "sns.barplot(x='revenue_at_risk', y='product_name', data=top_universal_underperformers, ax=axes[1], palette='Reds_r')\n",
        "axes[1].set_title('Top 5 \"Universal Underperformers\" (R&D/Product Issue)', fontsize=16)\n",
        "axes[1].set_xlabel('Financial Risk (Revenue at Risk)', fontsize=12)\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UhfG-8dNo8gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.11 Top 10 Return Risk Products**\n",
        "\n",
        "This is a tactical, high-urgency list. It answers the question: \"Which products are causing the most extreme customer anger right now?\" This list of products with the highest 1-star review rates should be immediately handed to the Quality Control and Product Management teams for investigation. It's less strategic than the analysis above, but it's a critical tool for immediate firefighting."
      ],
      "metadata": {
        "id": "YPdK-bJwtPLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Analysis 2: Top 10 \"Return Risk\" Products in Skincare ---\n",
        "print(\"--- Identifying Top 10 'Return Risk' Products (Highest 1-Star Rate) ---\")\n",
        "\n",
        "# 1. Isolate Skincare & Create 1-Star Flag\n",
        "skincare_df = df_sample[df_sample['primary_category'] == 'Skincare'].copy()\n",
        "skincare_df['is_1_star'] = skincare_df['rating_review'] == 1\n",
        "\n",
        "# 2. Calculate the 1-Star Rate per Product\n",
        "product_risk = skincare_df.groupby('product_name').agg(\n",
        "    total_reviews=('product_name', 'count'),\n",
        "    total_1_star=('is_1_star', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# 3. Filter for products with a significant number of reviews (>= 50)\n",
        "significant_products = product_risk[product_risk['total_reviews'] >= 50].copy()\n",
        "significant_products['return_risk_pct'] = (significant_products['total_1_star'] / significant_products['total_reviews']) * 100\n",
        "\n",
        "# 4. Identify and Visualize the Worst Offenders\n",
        "top_10_riskiest = significant_products.nlargest(10, 'return_risk_pct')\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='return_risk_pct', y='product_name', data=top_10_riskiest, palette='Reds_r')\n",
        "plt.title('Top 10 \"Return Risk\" Products in Skincare (Highest 1-Star Rate)', fontsize=18, weight='bold')\n",
        "plt.xlabel('1-Star Review Rate (%)', fontsize=12)\n",
        "plt.ylabel('Product', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CL1EbZWDtHhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.12 Contribution to Estimated Revenue by Price Tier**\n",
        "\n",
        "This analysis is foundational to the entire business strategy. It answers the most fundamental question: \"Where does our money actually come from?\" Understanding that the Mid-Range tier is the financial engine of the business provides the essential context for every other decision regarding marketing spend, inventory, and strategic focus."
      ],
      "metadata": {
        "id": "7mXJH2dqtUx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q squarify\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import squarify\n",
        "\n",
        "# --- Analysis 3: Strategic Importance of Price Tiers ---\n",
        "print(\"--- Visualizing Contribution to Estimated Revenue by Price Tier ---\")\n",
        "\n",
        "# 1. Calculate Estimated Revenue per Product\n",
        "product_details = df_sample[['product_name', 'price_usd']].drop_duplicates()\n",
        "product_review_counts = df_sample['product_name'].value_counts().reset_index()\n",
        "product_review_counts.columns = ['product_name', 'review_count']\n",
        "revenue_df = pd.merge(product_review_counts, product_details, on='product_name')\n",
        "revenue_df['estimated_revenue'] = revenue_df['review_count'] * revenue_df['price_usd']\n",
        "\n",
        "# 2. Segment Products into Price Tiers\n",
        "bins = [0, 25, 75, 150, 1000]\n",
        "labels = ['Budget (<$25)', 'Mid-Range ($25-$75)', 'High-End ($75-$150)', 'Luxury (>$150)']\n",
        "revenue_df['price_tier'] = pd.cut(revenue_df['price_usd'], bins=bins, labels=labels, right=False)\n",
        "revenue_df.dropna(subset=['price_tier'], inplace=True)\n",
        "\n",
        "# 3. Aggregate Revenue by Tier and Visualize with a Treemap\n",
        "tier_revenue = revenue_df.groupby('price_tier')['estimated_revenue'].sum()\n",
        "total_revenue = tier_revenue.sum()\n",
        "labels = [f'{label}\\n(${rev/1e6:.2f}M)\\n({rev/total_revenue*100:.1f}%)' for label, rev in tier_revenue.items()]\n",
        "colors = [plt.cm.viridis(i/float(len(labels))) for i in range(len(labels))]\n",
        "\n",
        "plt.figure(figsize=(16, 9))\n",
        "squarify.plot(sizes=tier_revenue, label=labels, color=colors, alpha=0.8, text_kwargs={'fontsize':14, 'weight':'bold'})\n",
        "plt.title('Contribution to Estimated Revenue by Price Tier', fontsize=20, weight='bold')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zrLfPsGztSR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.13 Customer Satisfaction by Skincare Problem**\n",
        "\n",
        "Why? This is a strategic analysis for R&D and product acquisition. It answers: \"Which customer problems are we failing to solve?\" By identifying the problems with the lowest average satisfaction ratings, it points to clear gaps in the market and in the current product portfolio that could be filled with new, more effective products."
      ],
      "metadata": {
        "id": "LxQisQFdtrcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Analysis 5: Customer Satisfaction by Skincare Problem ---\n",
        "print(\"--- Analyzing Customer Satisfaction by Skincare Problem ---\")\n",
        "\n",
        "# 1. Define Problem Cohorts\n",
        "problem_keywords = ['acne', 'wrinkle', 'dryness', 'pore', 'dark spot', 'redness', 'sensitive skin']\n",
        "analysis_df = df_sample.dropna(subset=['cleaned_review', 'rating_review'])\n",
        "\n",
        "# 2. Isolate, Analyze, and Measure Satisfaction\n",
        "problem_satisfaction = {}\n",
        "for problem in problem_keywords:\n",
        "    cohort_df = analysis_df[analysis_df['cleaned_review'].str.contains(problem)]\n",
        "    if len(cohort_df) >= 100:\n",
        "        avg_rating = cohort_df['rating_review'].mean()\n",
        "        problem_satisfaction[problem] = avg_rating\n",
        "\n",
        "# 3. Visualize the Performance\n",
        "satisfaction_df = pd.DataFrame(list(problem_satisfaction.items()), columns=['Problem', 'Average_Rating'])\n",
        "satisfaction_df = satisfaction_df.sort_values('Average_Rating', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = sns.barplot(x='Average_Rating', y='Problem', data=satisfaction_df, palette='coolwarm_r')\n",
        "plt.title('Customer Satisfaction by Skincare Problem', fontsize=18, weight='bold')\n",
        "plt.xlabel('Average Customer Rating (1-5)', fontsize=12)\n",
        "plt.ylabel('Customer-Stated Problem', fontsize=12)\n",
        "plt.xlim(4.0, 5.0)\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width - 0.01, p.get_y() + p.get_height()/2, f'{width:.2f}',\n",
        "             ha='right', va='center', color='white', weight='bold', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RGT7wg-Mt5cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.14 Distribution of Product Prices**\n",
        "\n",
        "Why? This is foundational context. While not directly actionable on its own, this chart is essential for understanding all the other price-related analyses. It shows that the vast majority of products are concentrated in the budget and mid-range tiers, which explains why those tiers are so financially important."
      ],
      "metadata": {
        "id": "LvBAeK1Dt_xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Analysis 6: Product Price Distribution ---\n",
        "print(\"--- Visualizing the Distribution of Product Prices ---\")\n",
        "\n",
        "# 1. Get unique product prices, filtering out extreme outliers for a clearer plot\n",
        "product_prices = df_sample.dropna(subset=['price_usd']).drop_duplicates(subset=['product_name'])\n",
        "filtered_prices = product_prices[product_prices['price_usd'] <= 250]\n",
        "\n",
        "# 2. Plot a histogram with a KDE overlay\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.histplot(filtered_prices['price_usd'], kde=True, color=\"mediumpurple\", bins=50)\n",
        "plt.title('Distribution of Product Prices (up to $250)', fontsize=16, weight='bold')\n",
        "plt.xlabel('Price (USD)', fontsize=12)\n",
        "plt.ylabel('Number of Products', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tC0nN-UtuFXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.15 Top 10 Most Reviewed Brands & Products**\n",
        "\n",
        "Why? This is important \"State of the Business\" EDA. It answers: \"Who are the biggest players in our ecosystem?\" While this doesn't drive strategy on its own, it provides crucial context. The brands and products on this list are the most visible and have the largest impact on overall customer perception."
      ],
      "metadata": {
        "id": "JTP3P8PmtYj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Analysis 7: Top 10 Most Reviewed Brands & Products ---\n",
        "print(\"--- Identifying Top 10 Most Reviewed Brands and Products ---\")\n",
        "\n",
        "# 1. Get the counts\n",
        "top_10_brands = df_sample['brand_name'].value_counts().nlargest(10)\n",
        "top_10_products = df_sample['product_name'].value_counts().nlargest(10)\n",
        "\n",
        "# 2. Visualize side-by-side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "fig.suptitle('Top 10 by Review Volume', fontsize=20, weight='bold')\n",
        "\n",
        "sns.barplot(x=top_10_brands.values, y=top_10_brands.index, ax=axes[0], palette='Greens_r')\n",
        "axes[0].set_title('Top 10 Most Reviewed Brands', fontsize=16)\n",
        "axes[0].set_xlabel('Number of Reviews', fontsize=12)\n",
        "axes[0].set_ylabel('Brand', fontsize=12)\n",
        "\n",
        "sns.barplot(x=top_10_products.values, y=top_10_products.index, ax=axes[1], palette='Blues_r')\n",
        "axes[1].set_title('Top 10 Most Reviewed Products', fontsize=16)\n",
        "axes[1].set_xlabel('Number of Reviews', fontsize=12)\n",
        "axes[1].set_ylabel('Product', fontsize=12)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "teQ0TS7SuNia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMrH1UuDuPID"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}